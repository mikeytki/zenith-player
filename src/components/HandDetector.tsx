import React, { useEffect, useRef, useState } from 'react';
import { FilesetResolver, GestureRecognizer } from "@mediapipe/tasks-vision";
import { usePlayerStore, GestureType } from '../store/usePlayerStore';
import { useShallow } from 'zustand/react/shallow';

// å¹³æ»‘ç³»æ•°
const LERP_FACTOR = 0.15;
// åŠ¨ä½œå†·å´æ—¶é—´ (æ¯«ç§’)ï¼Œé˜²æ­¢è¯¯è§¦è¿ç‚¹
const ACTION_COOLDOWN = 800;
// æ‰‹åŠ¿ç¡®è®¤å¸§æ•° - éœ€è¦è¿ç»­æ£€æµ‹åˆ°ç›¸åŒæ‰‹åŠ¿æ‰è§¦å‘
const GESTURE_CONFIRM_FRAMES = 3;
// ç½®ä¿¡åº¦é˜ˆå€¼
const CONFIDENCE_THRESHOLD = 0.5;

// æ»‘åŠ¨æ£€æµ‹å‚æ•°
const SWIPE_THRESHOLD = 0.15; // æ»‘åŠ¨è·ç¦»é˜ˆå€¼ï¼ˆå½’ä¸€åŒ–åæ ‡ï¼‰
const SWIPE_TIME_WINDOW = 500; // æ»‘åŠ¨æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰

interface PositionRecord {
  x: number;
  y: number;
  timestamp: number;
}

const HandDetector: React.FC = () => {
  const videoRef = useRef<HTMLVideoElement>(null);
  
  // 1. è·å–è¾“å…¥æ¨¡å¼å’Œ Setter (ç”¨äºè¯†åˆ«é€»è¾‘)
  const { 
    inputMode, 
    setGesture, 
    setCursorPosition, 
    setCameraStatus, 
    setInputMode 
  } = usePlayerStore(useShallow(state => ({
    inputMode: state.inputMode,
    setGesture: state.setGesture,
    setCursorPosition: state.setCursorPosition,
    setCameraStatus: state.setCameraStatus,
    setInputMode: state.setInputMode,
  })));

  // 2. è·å–æ’­æ”¾æ§åˆ¶åŠ¨ä½œ (ç”¨äºæ‰§è¡Œé€»è¾‘)
  const {
    play,
    pause,
    nextSong,
    prevSong,
    increaseVolume,
    decreaseVolume
  } = usePlayerStore(useShallow(state => ({
    play: state.play,
    pause: state.pause,
    nextSong: state.nextSong,
    prevSong: state.prevSong,
    increaseVolume: state.increaseVolume,
    decreaseVolume: state.decreaseVolume
  })));

  // Refs
  const lastCursorRef = useRef({ x: 0, y: 0 });
  const recognizerRef = useRef<GestureRecognizer | null>(null);
  const requestRef = useRef<number | null>(null);
  const lastActionTimeRef = useRef<number>(0);

  // æ‰‹åŠ¿ç¡®è®¤æœºåˆ¶
  const gestureHistoryRef = useRef<GestureType[]>([]);
  const confirmedGestureRef = useRef<GestureType>('NONE');

  // æ»‘åŠ¨æ£€æµ‹ï¼šä½ç½®å†å²è®°å½•
  const positionHistoryRef = useRef<PositionRecord[]>([]);
  const lastSwipeTimeRef = useRef<number>(0);

  const [isModelLoaded, setIsModelLoaded] = useState(false);

  // æ£€æµ‹æ»‘åŠ¨æ‰‹åŠ¿
  const detectSwipe = (currentX: number, currentY: number): GestureType => {
    const now = Date.now();
    
    // æ·»åŠ å½“å‰ä½ç½®åˆ°å†å²
    positionHistoryRef.current.push({ x: currentX, y: currentY, timestamp: now });
    
    // ç§»é™¤æ—¶é—´çª—å£ä¹‹å¤–çš„è®°å½•ï¼ˆä¿æŒ 500ms å†…çš„è½¨è¿¹ï¼‰
    while (
      positionHistoryRef.current.length > 0 &&
      now - positionHistoryRef.current[0].timestamp > SWIPE_TIME_WINDOW
    ) {
      positionHistoryRef.current.shift();
    }
    
    // éœ€è¦è¶³å¤Ÿçš„å†å²è®°å½•æ‰èƒ½æ£€æµ‹æ»‘åŠ¨
    if (positionHistoryRef.current.length < 3) {
      return 'NONE';
    }
    
    // æ£€æŸ¥å†·å´æ—¶é—´
    if (now - lastSwipeTimeRef.current < ACTION_COOLDOWN) {
      return 'NONE';
    }
    
    // è·å–æœ€æ—©ä¸€å¸§ä½œä¸ºæ¯”è¾ƒåŸºå‡†
    const startRecord = positionHistoryRef.current[0];

    if (!startRecord) {
      return 'NONE';
    }
    
    const deltaX = currentX - startRecord.x;
    const deltaY = currentY - startRecord.y;
    const absDeltaX = Math.abs(deltaX);
    const absDeltaY = Math.abs(deltaY);
    
    // åˆ¤æ–­æ˜¯æ°´å¹³æ»‘åŠ¨è¿˜æ˜¯å‚ç›´æ»‘åŠ¨
    if (absDeltaX > SWIPE_THRESHOLD && absDeltaX > absDeltaY * 1.5) {
      // æ°´å¹³æ»‘åŠ¨ï¼ˆæ³¨æ„ï¼šæ‘„åƒå¤´æ˜¯é•œåƒçš„ï¼Œæ‰€ä»¥æ–¹å‘ç›¸åï¼‰
      lastSwipeTimeRef.current = now;
      positionHistoryRef.current = []; // æ¸…ç©ºå†å²ï¼Œé˜²æ­¢è¿ç»­è§¦å‘
      return deltaX > 0 ? 'SWIPE_LEFT' : 'SWIPE_RIGHT'; // é•œåƒåè½¬
    } else if (absDeltaY > SWIPE_THRESHOLD && absDeltaY > absDeltaX * 1.5) {
      // å‚ç›´æ»‘åŠ¨
      lastSwipeTimeRef.current = now;
      positionHistoryRef.current = [];
      return deltaY > 0 ? 'SWIPE_DOWN' : 'SWIPE_UP';
    }
    
    return 'NONE';
  };

  // === æ ¸å¿ƒé€»è¾‘ï¼šæ‰§è¡Œæ‰‹åŠ¿å‘½ä»¤ ===
  const executeGestureAction = (gesture: GestureType) => {
    if (inputMode !== 'HAND') return;

    const now = Date.now();
    // æ£€æŸ¥å†·å´æ—¶é—´
    if (now - lastActionTimeRef.current < ACTION_COOLDOWN) return;

    if (gesture === 'OPEN') {
      console.log("ğŸ–ï¸ Gesture Trigger: PLAY");
      play();
      lastActionTimeRef.current = now;
    }
    else if (gesture === 'FIST') {
      console.log("âœŠ Gesture Trigger: PAUSE");
      pause();
      lastActionTimeRef.current = now;
    }
    else if (gesture === 'SWIPE_LEFT') {
      console.log("ğŸ‘ˆ Gesture Trigger: PREV SONG");
      prevSong(0);
      lastActionTimeRef.current = now;
    }
    else if (gesture === 'SWIPE_RIGHT') {
      console.log("ğŸ‘‰ Gesture Trigger: NEXT SONG");
      nextSong();
      lastActionTimeRef.current = now;
    }
    else if (gesture === 'SWIPE_UP') {
      console.log("ğŸ‘† Gesture Trigger: VOLUME UP");
      increaseVolume(0.15);
      lastActionTimeRef.current = now;
    }
    else if (gesture === 'SWIPE_DOWN') {
      console.log("ğŸ‘‡ Gesture Trigger: VOLUME DOWN");
      decreaseVolume(0.15);
      lastActionTimeRef.current = now;
    }
  };

  // === MediaPipe åˆå§‹åŒ– ===
  useEffect(() => {
    const initModel = async () => {
      try {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );
        const recognizer = await GestureRecognizer.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          numHands: 1
        });
        recognizerRef.current = recognizer;
        setIsModelLoaded(true);
        console.log("âœ… MediaPipe Model Loaded");
      } catch (error) {
        console.error("MediaPipe load error:", error);
      }
    };
    initModel();
  }, []);

  useEffect(() => {
    if (!isModelLoaded || inputMode !== 'HAND') {
        if (inputMode !== 'HAND' && videoRef.current && videoRef.current.srcObject) {
            const stream = videoRef.current.srcObject as MediaStream;
            stream.getTracks().forEach(track => track.stop());
            videoRef.current.srcObject = null;
        }
        if (requestRef.current) cancelAnimationFrame(requestRef.current);
        return;
    }

    const enableCam = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.onloadeddata = () => {
            setCameraStatus(true);
            predictWebcam();
          };
        }
      } catch (err) {
        console.error("Camera denied:", err);
        setCameraStatus(false);
        setInputMode('MOUSE');
      }
    };

    enableCam();

    return () => {
      if (requestRef.current) cancelAnimationFrame(requestRef.current);
      if (videoRef.current && videoRef.current.srcObject) {
        const stream = videoRef.current.srcObject as MediaStream;
        stream.getTracks().forEach(track => track.stop());
      }
    };
  }, [isModelLoaded, inputMode, setCameraStatus, setInputMode]);

  const predictWebcam = () => {
    if (!videoRef.current || !recognizerRef.current || inputMode !== 'HAND') return;

    const nowInMs = Date.now();
    if (videoRef.current.videoWidth > 0 && videoRef.current.videoHeight > 0) {
        const results = recognizerRef.current.recognizeForVideo(videoRef.current, nowInMs);

        if (results.landmarks && results.landmarks.length > 0) {
          const landmarks = results.landmarks[0];
          const mediapipeGesture = results.gestures.length > 0 ? results.gestures[0][0].categoryName : '';
          const confidence = results.gestures.length > 0 ? results.gestures[0][0].score : 0;

          // è·å–æ‰‹æŒä¸­å¿ƒä½ç½®ï¼ˆç”¨äºæ»‘åŠ¨æ£€æµ‹ï¼‰
          // ä½¿ç”¨æ‰‹è…•(0)å’Œä¸­æŒ‡æ ¹éƒ¨(9)çš„ä¸­ç‚¹ä½œä¸ºæ‰‹æŒä¸­å¿ƒ
          const wrist = landmarks[0];
          const middleBase = landmarks[9];
          const palmCenterX = (wrist.x + middleBase.x) / 2;
          const palmCenterY = (wrist.y + middleBase.y) / 2;

          // è·å–é£ŸæŒ‡ä½ç½®ï¼ˆç”¨äºå…‰æ ‡ï¼‰
          const indexTip = landmarks[8];

          let myGesture: GestureType = 'NONE';

          // é¦–å…ˆæ£€æµ‹æ»‘åŠ¨æ‰‹åŠ¿ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
          const swipeGesture = detectSwipe(palmCenterX, palmCenterY);
          if (swipeGesture !== 'NONE') {
            myGesture = swipeGesture;
            // æ»‘åŠ¨æ‰‹åŠ¿ç«‹å³æ‰§è¡Œ
            setGesture(myGesture);
            executeGestureAction(myGesture);
            // é‡ç½®é™æ€æ‰‹åŠ¿å†å²
            gestureHistoryRef.current = [];
            confirmedGestureRef.current = 'NONE';
          } else if (confidence > CONFIDENCE_THRESHOLD) {
            // åªæœ‰é«˜ç½®ä¿¡åº¦æ—¶æ‰æ£€æµ‹é™æ€æ‰‹åŠ¿
            if (mediapipeGesture === 'Open_Palm') {
              myGesture = 'OPEN';
            } else if (mediapipeGesture === 'Closed_Fist') {
              myGesture = 'FIST';
            } else if (mediapipeGesture === 'Victory' || mediapipeGesture === 'Pointing_Up') {
              myGesture = 'POINT';
            }

            // é™æ€æ‰‹åŠ¿ç¡®è®¤æœºåˆ¶ï¼šéœ€è¦è¿ç»­å¤šå¸§æ£€æµ‹åˆ°ç›¸åŒæ‰‹åŠ¿
            if (myGesture !== 'NONE' && myGesture !== 'POINT') {
              gestureHistoryRef.current.push(myGesture);
              if (gestureHistoryRef.current.length > GESTURE_CONFIRM_FRAMES) {
                gestureHistoryRef.current.shift();
              }

              // æ£€æŸ¥æœ€è¿‘çš„å¸§æ˜¯å¦éƒ½æ˜¯åŒä¸€ä¸ªæ‰‹åŠ¿
              if (gestureHistoryRef.current.length === GESTURE_CONFIRM_FRAMES) {
                const allSame = gestureHistoryRef.current.every(g => g === myGesture);
                if (allSame && confirmedGestureRef.current !== myGesture) {
                  confirmedGestureRef.current = myGesture;
                  setGesture(myGesture);
                  // ç›´æ¥æ‰§è¡ŒåŠ¨ä½œ
                  executeGestureAction(myGesture);
                  // æ‰§è¡Œåé‡ç½®ï¼Œé˜²æ­¢é‡å¤è§¦å‘
                  gestureHistoryRef.current = [];
                  confirmedGestureRef.current = 'NONE';
                }
              }
            } else if (myGesture === 'POINT') {
              // POINT ç«‹å³æ›´æ–°ï¼ˆç”¨äºå…‰æ ‡æ§åˆ¶ï¼‰
              setGesture(myGesture);
            } else {
              // NONE æ—¶ä¸ç«‹å³æ¸…ç©ºå†å²ï¼Œä¿æŒä¸€å®šå®¹é”™
              // åªæ›´æ–°æ˜¾ç¤ºçŠ¶æ€
              setGesture('NONE');
            }
          } else {
            // ä½ç½®ä¿¡åº¦æ—¶ä¸æ¸…ç©ºå†å²ï¼Œä¿æŒå®¹é”™æ€§
            // è¿™æ ·å³ä½¿ä¸­é—´æœ‰å‡ å¸§ç½®ä¿¡åº¦ä½ï¼Œä¹Ÿä¸ä¼šæ‰“æ–­æ‰‹åŠ¿ç¡®è®¤
          }

          // æ›´æ–°å…‰æ ‡ä½ç½®
          const rawX = indexTip.x;
          const rawY = indexTip.y;
          const mirroredX = 1 - rawX;
          const targetX = (mirroredX * 2) - 1;
          const targetY = -(rawY * 2) + 1;

          const smoothX = lastCursorRef.current.x + (targetX - lastCursorRef.current.x) * LERP_FACTOR;
          const smoothY = lastCursorRef.current.y + (targetY - lastCursorRef.current.y) * LERP_FACTOR;

          lastCursorRef.current = { x: smoothX, y: smoothY };
          setCursorPosition(smoothX, smoothY);
        } else {
          setGesture('NONE');
          gestureHistoryRef.current = [];
          confirmedGestureRef.current = 'NONE';
          // ä¸æ¸…ç©ºä½ç½®å†å²ï¼Œä¿æŒæ»‘åŠ¨æ£€æµ‹çš„è¿ç»­æ€§
        }
    }

    // åªåœ¨ HAND æ¨¡å¼ä¸‹ç»§ç»­å¾ªç¯
    if (inputMode === 'HAND') {
      requestRef.current = requestAnimationFrame(predictWebcam);
    }
  };

  return (
    <video 
      ref={videoRef} 
      autoPlay 
      playsInline 
      muted
      className="hidden fixed top-0 left-0 w-32 h-32 opacity-0 pointer-events-none" 
    />
  );
};

export default HandDetector;
